version: "3"
services:

  web:
    image: "tumar/nginx:latest"
    restart: "always"
    expose:
      - "80"
    environment:
      - "DOMAIN_NAME=${DOMAIN_NAME}"
      - "PROXY_PASS=http://app:80"
    volumes:
      - "./config/:/etc/nginx/conf.d/"
      - ./static:/static
      - ./media:/media
    networks:
      - "tumar"
    labels:
      - "traefik.frontend.rule=Host:${DOMAIN_NAME}"
    command: /bin/bash -c "nginx -g 'daemon off;'"

  app:
    image: "tumar/app:latest"
    restart: "always"
    user: ${CURRENT_UID}
    expose:
      - "3000"
    networks:
      - "tumar"
      - "main_db"
    volumes:
      - ".:/code"
      - ./static:/code/static
      - ./media:/code/media
    command: >
      bash -c "./manage.py collectstatic --noinput &&
              ./manage.py migrate &&
              ./manage.py compilemessages &&
              uwsgi --ini config/uwsgi.ini"

  memcached:
    image: memcached:1.6.5
    expose:
      - "11211"
    networks:
      - "tumar"

  worker:
    image: "tumar/app:latest"
    restart: "always"
    user: ${CURRENT_UID}
    networks:
      - "tumar"
      - "main_db"
    volumes:
      - ".:/code"
    command: >
      bash -c "celery -A tumar worker -Q tumar_celerybeat,tumar_handler_process_cadastres -c 3 -n tumar_worker -l INFO"
  
  celerybeat:
    image: "tumar/app:latest"
    restart: "always"
    user: ${CURRENT_UID}
    networks:
      - "tumar"
      - "main_db"
    volumes:
      - ".:/code"
    command: >
      bash -c "celery beat -A tumar -l INFO --pidfile /tmp/celerybeat.pid -s /tmp/celerybeat-schedule"

networks:
  tumar:
    external: true
  main_db:
    external: true
